{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to flipkart1_cakes.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Function to scrape product information from a given URL\n",
    "def scrape_flipkart(url):\n",
    "    # Initialize empty lists to store product information\n",
    "    product_names = []\n",
    "    product_ratings = []\n",
    "    product_review_counts = []\n",
    "    product_prices = []\n",
    "\n",
    "    # Loop through each page of results, up to 10 pages\n",
    "    for page_number in range(1, 20):\n",
    "        # Sending a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Finding all the products on the page\n",
    "        products = soup.find_all('div', class_=\"_1AtVbE\")\n",
    "\n",
    "        # Looping through each product and extracting information\n",
    "        for product in products:\n",
    "            # Extracting product name\n",
    "            name = product.find('a', class_=\"s1Q9rs\")\n",
    "            product_name = name.text.strip() if name else \"Name not available\"\n",
    "            product_names.append(product_name)\n",
    "\n",
    "            # Extracting product rating\n",
    "            rating = product.find('div', class_=\"_3LWZlK\")\n",
    "            product_rating = rating.text.strip() if rating else \"Not available\"\n",
    "            product_ratings.append(product_rating)\n",
    "\n",
    "            # Extracting review count\n",
    "            review_count = product.find('span', class_=\"_2_R_DZ\")\n",
    "            product_review_count = review_count.text.strip() if review_count else \"No reviews\"\n",
    "            product_review_counts.append(product_review_count)\n",
    "\n",
    "            # Extracting product price\n",
    "            price = product.find('div', class_=\"_30jeq3\")\n",
    "            product_price = price.text.strip() if price else \"Price not available\"\n",
    "            product_prices.append(product_price)\n",
    "\n",
    "        # Check if there is a next page\n",
    "        next_button = soup.find('a', class_=\"_1LKTO3\")\n",
    "        if next_button and page_number < 10: # Only continue if there is a next page and we haven't reached 10 pages\n",
    "            url = \"https://www.flipkart.com\" + next_button['href'] # Update URL for the next page\n",
    "            time.sleep(2) # Add a short delay to avoid overwhelming the server\n",
    "        else:\n",
    "            break  # Break the loop if there is no next page or we have reached 10 pages\n",
    "\n",
    "    # Return the scraped product information\n",
    "    return product_names, product_ratings, product_review_counts, product_prices\n",
    "\n",
    "# URL of the Flipkart page for chocolates\n",
    "url = \"https://www.flipkart.com/search?q=chocolates%20cakes&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off\"\n",
    "\n",
    "# Scrape product information\n",
    "product_names, product_ratings, product_review_counts, product_prices = scrape_flipkart(url)\n",
    "\n",
    "# Create a CSV file and write the data\n",
    "with open('flipkart_cakes.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'Rating', 'Review Count', 'Price'])\n",
    "    for name, rating, review_count, price in zip(product_names, product_ratings, product_review_counts, product_prices):\n",
    "        writer.writerow([name, rating, review_count, price])\n",
    "\n",
    "print(\"Data has been saved to flipkart1_cakes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to cadbury_cakes.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# Function to scrape product information from a given URL\n",
    "def scrape_flipkart(url):\n",
    "    # Initialize empty lists to store product information\n",
    "    product_names = []\n",
    "    product_ratings = []\n",
    "    product_review_counts = []\n",
    "    product_prices = []\n",
    "\n",
    "    # Loop through each page of results, up to 10 pages\n",
    "    for page_number in range(1, 20):\n",
    "        # Sending a GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Parsing the HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # Finding all the products on the page\n",
    "        products = soup.find_all('div', class_=\"_1AtVbE\")\n",
    "\n",
    "        # Looping through each product and extracting information\n",
    "        for product in products:\n",
    "            # Extracting product name\n",
    "            name = product.find('a', class_=\"s1Q9rs\")\n",
    "            product_name = name.text.strip() if name else \"Name not available\"\n",
    "            product_names.append(product_name)\n",
    "\n",
    "            # Extracting product rating\n",
    "            rating = product.find('div', class_=\"_3LWZlK\")\n",
    "            product_rating = rating.text.strip() if rating else \"Not available\"\n",
    "            product_ratings.append(product_rating)\n",
    "\n",
    "            # Extracting review count\n",
    "            review_count = product.find('span', class_=\"_2_R_DZ\")\n",
    "            product_review_count = review_count.text.strip() if review_count else \"No reviews\"\n",
    "            product_review_counts.append(product_review_count)\n",
    "\n",
    "            # Extracting product price\n",
    "            price = product.find('div', class_=\"_30jeq3\")\n",
    "            product_price = price.text.strip() if price else \"Price not available\"\n",
    "            product_prices.append(product_price)\n",
    "\n",
    "        # Check if there is a next page\n",
    "        next_button = soup.find('a', class_=\"_1LKTO3\")\n",
    "        if next_button and page_number < 10: # Only continue if there is a next page and we haven't reached 10 pages\n",
    "            url = \"https://www.flipkart.com\" + next_button['href'] # Update URL for the next page\n",
    "            time.sleep(2) # Add a short delay to avoid overwhelming the server\n",
    "        else:\n",
    "            break  # Break the loop if there is no next page or we have reached 10 pages\n",
    "\n",
    "    # Return the scraped product information\n",
    "    return product_names, product_ratings, product_review_counts, product_prices\n",
    "\n",
    "# URL of the Flipkart page for chocolates\n",
    "url = \"https://www.flipkart.com/search?q=cadbury+cake+%26+pastry&sid=eat%2Ceeg%2Chep&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_13_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_13_na_na_na&as-pos=1&as-type=RECENT&suggestionId=cadbury+cake+%26+pastry%7CCake+Mix&requestId=d507f765-00af-4e5d-8bc5-633427e482f2&as-searchtext=cadbury%20cakes\"\n",
    "\n",
    "# Scrape product information\n",
    "product_names, product_ratings, product_review_counts, product_prices = scrape_flipkart(url)\n",
    "\n",
    "# Create a CSV file and write the data\n",
    "with open('cadbury_cakes.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Name', 'Rating', 'Review Count', 'Price'])\n",
    "    for name, rating, review_count, price in zip(product_names, product_ratings, product_review_counts, product_prices):\n",
    "        writer.writerow([name, rating, review_count, price])\n",
    "\n",
    "print(\"Data has been saved to cadbury_cakes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
